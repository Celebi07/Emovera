{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance class\n",
    "class L1Dist(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Magic happens here - similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    \n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # Load in the image \n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    # Preprocessing steps - resizing the image to be 105x105x3\n",
    "    img = tf.image.resize(img, (105,105))\n",
    "    # Scale image to be between 0 and 1 \n",
    "    img = img / 255.0\n",
    "\n",
    "    # Return image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANC_PATH = os.path.join('VerificationImages', 'Image') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing complete.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained Haar cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Establish a connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "capturing = False\n",
    "capture_count = 0\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "   \n",
    "    # Cut down frame to 250x250px\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "        # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangles around the detected faces on the display frame\n",
    "    display_frame = frame.copy()\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(display_frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the frame with face detection rectangles\n",
    "    cv2.imshow('Face Detection', display_frame)\n",
    "\n",
    "    # Check if the 'v' key is pressed and a face is detected\n",
    "    key = cv2.waitKey(30)\n",
    "    if key & 0xFF == ord('v') and len(faces) > 0:\n",
    "        capturing = True \n",
    "\n",
    "    # Capture screenshots when capturing is True\n",
    "    if capturing and len(faces) > 0 and capture_count < 20:\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out anchor image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        # Show image back to screen\n",
    "        cv2.imshow('Image Collection', frame) \n",
    "        capture_count += 1\n",
    "        cv2.waitKey(30)\n",
    "    elif capture_count >= 20:\n",
    "        capturing = False\n",
    "        print(\"Capturing complete.\")\n",
    "        break\n",
    "\n",
    "    # Check if the 'q' key is pressed to quit\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "siamese_model = tf.keras.models.load_model('snn_kash.h5', \n",
    "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VerificationImages\\Image\\b786f10f-3de6-11ee-b3ce-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b79e81dd-3de6-11ee-baa0-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b7aee594-3de6-11ee-b0ce-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b7bf4477-3de6-11ee-9781-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b7cd9559-3de6-11ee-b9e5-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b7de0f03-3de6-11ee-9d48-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b7ee725a-3de6-11ee-9ec8-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b7ff1230-3de6-11ee-8fc6-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b80fa1f7-3de6-11ee-ac6f-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b822b20a-3de6-11ee-bdaf-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b8333008-3de6-11ee-813b-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b8417771-3de6-11ee-8788-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b8547061-3de6-11ee-bbd4-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b864d865-3de6-11ee-9555-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b8733ff2-3de6-11ee-b17c-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b881a2b6-3de6-11ee-99cc-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b8928b3d-3de6-11ee-8f2e-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b8a32fb2-3de6-11ee-b486-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b8b1625e-3de6-11ee-bac4-3003c8e2f0f6.jpg\n",
      "VerificationImages\\Image\\b8bfa49d-3de6-11ee-a998-3003c8e2f0f6.jpg\n"
     ]
    }
   ],
   "source": [
    "for image in os.listdir(os.path.join('VerificationImages', 'Image')):\n",
    "    validation_img = os.path.join('VerificationImages', 'Image', image)\n",
    "    print(validation_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model, detection_threshold, verification_threshold):\n",
    "    # Build results array\n",
    "    results = []\n",
    "    for image in os.listdir(os.path.join('VerificationImages', 'Image')):\n",
    "        input_img = preprocess(os.path.join('VerificationImages', 'InputImage', 'input_image.jpg'))\n",
    "        validation_img = preprocess(os.path.join('VerificationImages', 'Image', image))\n",
    "        \n",
    "        # Make Predictions \n",
    "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
    "        results.append(result)\n",
    "    \n",
    "    # Detection Threshold: Metric above which a prediciton is considered positive \n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "    \n",
    "    # Verification Threshold: Proportion of positive predictions / total positive samples \n",
    "    verification = detection / len(os.listdir(os.path.join('VerificationImages', 'Image'))) \n",
    "    verified = verification > verification_threshold\n",
    "    \n",
    "    return results, verified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image saved as VerificationImages\\InputImage\\input_image.jpg\n",
      "Input image saved as VerificationImages\\InputImage\\input_image.jpg\n"
     ]
    }
   ],
   "source": [
    "# Create the \"VerificationImage/InputImage\" folders if they don't exist\n",
    "if not os.path.exists(\"VerificationImages/InputImage\"):\n",
    "    os.makedirs(\"VerificationImages/InputImage\")\n",
    "\n",
    "# Load the pre-trained Haar cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the default camera (camera index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "\n",
    "    frame_roi = frame[120:120+250, 200:200+250, :]\n",
    "    \n",
    "    # Display the verification frame\n",
    "    cv2.imshow('Verification', frame_roi)\n",
    "\n",
    "    key = cv2.waitKey(10) & 0xFF\n",
    "\n",
    "    if key == ord('v'):\n",
    "        input_image_path = os.path.join('VerificationImages', 'InputImage', 'input_image.jpg')\n",
    "        cv2.imwrite(input_image_path, frame_roi)\n",
    "        print(f\"Input image saved as {input_image_path}\")\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Run verification using your 'verify' function and 'siamese_model'\n",
    "results, verified = verify(siamese_model, 0.5, 0.5) \n",
    "print(verified) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
